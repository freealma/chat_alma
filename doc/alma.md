---
version: 0.0.2
path: alma.md
description: "Terminal cli de ayuda resiliente que aprende de las conversaciones"
changelog: "Se documento la version 0.0.2 con manejo de memorias con LLM"
---

# Alma CLI - Documentaci√≥n T√©cnica

## üìã Especificaciones T√©cnicas

### Versi√≥n: 0.0.2
**Estado**: MVP Mejorado con B√∫squeda Inteligente  
**√öltima Actualizaci√≥n**: 2025-11-21

## üèóÔ∏è Arquitectura del Sistema

### Componentes Principales

```
Alma CLI Architecture
‚îú‚îÄ‚îÄ Frontend Layer
‚îÇ   ‚îî‚îÄ‚îÄ alma.py (CLI Interface + Search Mode Controller)
‚îú‚îÄ‚îÄ Business Logic
‚îÇ   ‚îú‚îÄ‚îÄ MemoryManager (memory.py) - B√∫squeda H√≠brida
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search_memories_simple() - Keywords
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ search_memories_enhanced() - LLM Re-ranking
‚îÇ   ‚îî‚îÄ‚îÄ DeepSeek API Client (Doble uso: Chat + Re-ranking)
‚îú‚îÄ‚îÄ Data Layer
‚îÇ   ‚îî‚îÄ‚îÄ SQLite Database con Schema UUID
‚îî‚îÄ‚îÄ Infrastructure
    ‚îî‚îÄ‚îÄ Docker Container
```

### Flujo de Datos Mejorado

```mermaid
graph TD
    A[User Input] --> B[CLI Parser]
    B --> C{Is Command?}
    C -->|Yes| D[Command Handler]
    C -->|No| E{Search Mode?}
    E -->|Simple| F[Keyword Search]
    E -->|Smart| G[Hybrid Search]
    F --> H[Context Building]
    G --> I[LLM Re-ranking]
    I --> H
    D --> J[Execute Command]
    H --> K[DeepSeek API Call]
    K --> L[Response Processing]
    L --> M[Output to User]
    J --> M
```

## üîå Configuraci√≥n

### Variables de Entorno

| Variable | Requerido | Default | Descripci√≥n |
|----------|-----------|---------|-------------|
| `DEEPSEEK_API_KEY` | ‚úÖ | - | API Key para DeepSeek (Chat + Re-ranking) |
| `DB_PATH` | ‚ùå | `/alma/db/alma.db` | Ruta de la base de datos |

## üß† Sistema de Memoria Mejorado

### B√∫squeda H√≠brida

```python
def search_memories_enhanced(query: str, use_llm: bool = True) -> List[Dict]:
    """B√∫squeda h√≠brida: keywords + optional LLM re-ranking"""
    # 1. B√∫squeda inicial por keywords
    candidates = search_memories_simple(query, limit * 2)
    
    if use_llm and len(candidates) > 1:
        # 2. Re-ranking con LLM para relevancia sem√°ntica
        return rerank_with_llm(query, candidates)[:limit]
    
    return candidates[:limit]
```

### Algoritmos de B√∫squeda

#### Modo Simple (Keyword-based)
- **Velocidad**: ‚ö°Ô∏è Muy r√°pido
- **Precisi√≥n**: ‚úÖ Buena para coincidencias exactas
- **Uso**: B√∫squedas generales, listado r√°pido

#### Modo Smart (LLM-enhanced)  
- **Velocidad**: üê¢ Moderado (+ llamada API)
- **Precisi√≥n**: üéØ Excelente relevancia sem√°ntica
- **Uso**: Consultas complejas, contexto espec√≠fico

### Re-ranking con LLM

```python
def _rerank_with_llm(query: str, memories: List[Dict]) -> List[int]:
    """Usa DeepSeek para ordenar memorias por relevancia"""
    prompt = f"""Eval√∫a relevancia con: "{query}"
    
Memorias:
{chr(10).join([f"{i+1}. {m['content'][:150]}..." for i, m in enumerate(memories)])}

Devuelve SOLO n√∫meros de las 5 m√°s relevantes en orden:"""
    
    response = _call_llm_api(prompt, max_tokens=100)
    return parse_ranked_indices(response)
```

## üóÑÔ∏è Base de Datos

### Schema Design (Sin Cambios)

```sql
-- Tabla principal de memorias (UUID-based)
CREATE TABLE IF NOT EXISTS memories (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    uuid TEXT UNIQUE NOT NULL DEFAULT (lower(hex(randomblob(4))) || '-' || lower(hex(randomblob(2))) || '-4' || substr(lower(hex(randomblob(2))), 2) || '-a' || substr(lower(hex(randomblob(2))), 2) || '-' || lower(hex(randomblob(6)))),
    content TEXT NOT NULL,
    tags TEXT,
    project TEXT,
    theme TEXT,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    importance INTEGER DEFAULT 2 CHECK (importance BETWEEN 1 AND 5),
    related_to TEXT CHECK(related_to IN ('architecture', 'philosophy', 'pentesting', 'programming')),
    memory_type TEXT CHECK(memory_type IN ('institutional', 'context', 'alma', 'bird', 'architecture', 'structure', 'function')),
    use_count INTEGER DEFAULT 0,
    last_used DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

### Inicializaci√≥n de Datos

```bash
# Cargar 30 memorias base sobre Alma
./src/alma/utils/inject_memories.sh
```

Las memorias incluyen:
- **Institutional**: Conocimiento fundamental del sistema
- **Structure**: Arquitectura y componentes
- **Function**: Comportamiento y comandos
- **Alma**: Visi√≥n y roadmap futuro

## üîç Algoritmos de B√∫squeda Actualizados

### Extracci√≥n de Keywords (Modo Simple)

```python
def _extract_keywords(text: str) -> List[str]:
    stop_words = {'el', 'la', 'los', 'las', 'de', 'en', 'y', 'o', 'pero', 'para'}
    words = re.findall(r'\b[a-z√°√©√≠√≥√∫√±]{3,20}\b', text.lower())
    return [word for word in words if word not in stop_words][:10]
```

### Scoring H√≠brido (Modo Smart)

1. **Coincidencia Keywords** (B√∫squeda inicial)
2. **Re-ranking Sem√°ntico** (LLM evaluation)
3. **Importancia + Uso** (Ordenamiento final)

## ü§ñ Integraci√≥n DeepSeek API

### Uso Doble de la API

#### 1. Generaci√≥n de Respuestas
```python
# Chat principal
data = {
    "model": "deepseek-chat",
    "messages": [
        {"role": "system", "content": f"Eres Alma...\n{context}"},
        {"role": "user", "content": message}
    ],
    "temperature": 0.7,
    "max_tokens": 1000
}
```

#### 2. Re-ranking de Memorias
```python
# Re-ranking optimizado
data = {
    "model": "deepseek-chat", 
    "messages": [{"role": "user", "content": rerank_prompt}],
    "temperature": 0.1,  # Baja para consistencia
    "max_tokens": 100    # Respuesta corta
}
```

## üê≥ Docker Implementation

### Build Optimizado

```dockerfile
FROM python:3.11-alpine

WORKDIR /alma

RUN apk add --no-cache sqlite

COPY pyproject.toml .
RUN pip install --no-cache-dir -e .

COPY meta/schema.sql .
COPY src/ ./src/
RUN mkdir -p db

CMD ["python", "-c", "from alma.alma import main; main()"]
```

### Ejecuci√≥n Recomendada

```bash
# Build una vez
docker build -t alma-cli .

# Ejecutar interactivamente
docker run -it --env-file .env -v $(pwd)/db:/alma/db alma-cli
```

## üìä M√©tricas y Monitoreo

### Estad√≠sticas Recopiladas

- Total de memorias y distribuci√≥n por tipo
- Eficiencia de b√∫squeda (simple vs smart)
- Tasa de uso de memorias
- Performance de llamadas API

### Comandos de Diagn√≥stico

```bash
üßë T√∫: /searchmode
üîç Modo de b√∫squeda cambiado a: smart (con LLM)

üßë T√∫: /memories
üìö √öltimas memorias (re-rankeadas por relevancia):
  1. Alma es un CLI chat especializado... (usos: 5)
  2. El sistema de Alma usa SQLite con UUIDs... (usos: 3)
```

## üîí Consideraciones de Seguridad

### API Key Management
- **Doble uso**: Misma key para chat y re-ranking
- **Rate limiting**: Control de llamadas consecutivas
- **Timeout**: 30 segundos por defecto

### Data Protection
- **Local-first**: Toda la data permanece local
- **UUIDs**: Identificadores an√≥nimos
- **No PII**: Solo contenido t√©cnico, no datos personales

## üöÄ Roadmap

### V0.1.0 (Pr√≥xima)
- [ ] Comando `/stats` para m√©tricas del sistema
- [ ] Comando `/optimize` para mantenimiento de BD
- [ ] Cache de embeddings para b√∫squedas m√°s r√°pidas
- [ ] Sistema de plugins para herramientas de pentesting

### V0.2.0 (Futuro)
- [ ] Integraci√≥n con nmap, metasploit, burp suite
- [ ] Sistema de relaciones entre memorias
- [ ] Export/import de bases de conocimiento
- [ ] API REST para integraciones

## üß™ Testing Strategy

### Pruebas de B√∫squeda H√≠brida

```python
def test_hybrid_search_fallback():
    """Prueba fallback a b√∫squeda simple cuando LLM falla"""
    manager = MemoryManager(api_key="invalid_key")
    results = manager.search_memories_enhanced("test query", use_llm=True)
    assert len(results) > 0  # Debe fallar gracefulmente a simple search

def test_search_mode_switching():
    """Prueba cambio entre modos de b√∫squeda"""
    # Verificar que /searchmode alterna correctamente
```

## üêõ Troubleshooting Avanzado

### Error: LLM Re-ranking Timeout
**S√≠ntoma**: B√∫squeda smart muy lenta
**Soluci√≥n**: Cambiar a modo simple con `/searchmode`

### Error: API Rate Limit Exceeded
**S√≠ntoma**: Errores 429 en b√∫squedas smart
**Soluci√≥n**: Sistema autom√°ticamente usa fallback a simple

### Error: Memory Consistency
**S√≠ntoma**: Resultados inconsistentes entre modos
**Soluci√≥n**: Ejecutar script de inicializaci√≥n para reset

## üîó Dependencies

### Runtime
- `python:3.11-alpine` - Base image optimizada
- `requests>=2.25.0` - HTTP client para DeepSeek API
- `sqlite3` - Base de datos embebida

### No Dependencies Externas
- **Sin vector databases** - B√∫squeda sem√°ntica via API
- **Sin ORM complejo** - SQLite directo
- **Sin web frameworks** - CLI puro

---

**Documentaci√≥n Mantenida por**: Alma CLI Team  
**√öltima Revisi√≥n**: 2024-04-06  
**Versi√≥n Documentada**: 0.0.2
```